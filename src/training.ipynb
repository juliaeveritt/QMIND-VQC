{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is just a celled version of `main.py` for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from model import QuanvNet, QuanvLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "n_train_samples = 2\n",
    "n_test_samples = 16\n",
    "batch_size_train = 1\n",
    "batch_size_test = 16\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 123\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "im_size = 8  # resize images to this width and height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X_train = datasets.MNIST(\n",
    "    root='./data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Resize((im_size,im_size)),\n",
    "    ])\n",
    ")\n",
    "# Select only labels 0 and 1\n",
    "idx = np.append(np.where(X_train.targets == 0)[0][:n_train_samples], \n",
    "                np.where(X_train.targets == 1)[0][:n_train_samples])\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "\n",
    "# Load testing data\n",
    "X_test = datasets.MNIST(\n",
    "    root='./data', train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Resize((im_size,im_size)),\n",
    "    ])\n",
    ")\n",
    "idx = np.append(np.where(X_test.targets == 0)[0][:n_test_samples], \n",
    "                np.where(X_test.targets == 1)[0][:n_test_samples])\n",
    "\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net class for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomQunvNet(nn.Module):\n",
    "    \"\"\"Layout of Quanv model that can be modified on the fly\"\"\"\n",
    "    def __init__(self, input_size=8, shots=128):\n",
    "        super(CustomQunvNet, self).__init__()\n",
    "\n",
    "        self.fc_size = (input_size - 3)**2 * 16  # output size of convloving layers\n",
    "        self.quanv = QuanvLayer(in_channels=1, out_channels=2, kernel_size=2, shots=shots)\n",
    "        self.conv = nn.Conv2d(2, 16, kernel_size=3)\n",
    "        # self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(self.fc_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # this is where we build our entire network\n",
    "        # whatever layers of quanvolution, pooling,\n",
    "        # convolution, dropout, flattening,\n",
    "        # fully connectecd layers, go here\n",
    "        x = F.relu(self.quanv(x))\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = x.view(-1, self.fc_size)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomQunvNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "test_data, test_target = next(iter(test_loader))  # just access first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    # keep track of accuracy and loss for a given epoch\n",
    "    epoch_train_acc = []\n",
    "    epoch_train_loss = []\n",
    "    # TODO: validation score\n",
    "    epoch_test_acc = []\n",
    "    epoch_test_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        pred = output.argmax(axis=1)\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss.append(loss.item())\n",
    "\n",
    "        acc = (pred == target).float().sum()/ len(target)\n",
    "        epoch_train_acc.append(acc.item())\n",
    "        \n",
    "        # testing acc\n",
    "        test_pred = model(test_data).argmax(axis=1)\n",
    "        test_acc = (test_pred == test_target).float().sum()/ len(test_target)\n",
    "        epoch_test_acc.append(test_acc.item())\n",
    "    \n",
    "    torch.save(model.state_dict(), f'model_dict_e{epoch}')\n",
    "    \n",
    "    train_losses.append(sum(epoch_train_loss) / len(epoch_train_loss))\n",
    "    train_accs.append(sum(epoch_train_acc) / len(epoch_train_acc))\n",
    "    test_accs.append(sum(epoch_test_acc) / len(epoch_test_acc))\n",
    "    \n",
    "    print('Training [{:.0f}%] \\t Loss: {:.4f} \\t Accuracy: {:.4} \\t Test Accuracy: {:.4}'.format(\n",
    "        100. * (epoch + 1) / n_epochs, train_losses[-1], train_accs[-1], test_accs[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(len(train_losses)), train_losses, color='blue')\n",
    "# plt.scatter(test_counter, test_losses, color='red')\n",
    "# plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "plt.savefig(\"training.pdf\", dpi=800)\n",
    "plt.show()\n",
    "\n",
    "np.save('train_loss', train_losses)\n",
    "np.save('train_acc', train_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
